import os
import shutil
# --- S·ª¨A L·ªñI: D√πng th∆∞ vi·ªán m·ªõi langchain_text_splitters ---
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# --- C·∫§U H√åNH ---
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
DATA_ROOT = os.path.join(PROJECT_ROOT, "data_raw")
DB_PATH = os.path.join(PROJECT_ROOT, "vector_db")

# C√°c t·ª´ kh√≥a nh·∫≠n di·ªán
KNOWN_PUBLISHERS = ["CanhDieu", "KetNoiTriThuc", "ChanTroiSangTao"]
KNOWN_TYPES = ["SGK", "SGV", "SBT"]

def get_metadata_from_path(file_path):
    path_parts = file_path.split(os.sep)
    metadata = {
        "grade": "Unknown",
        "publisher": "TongHop",
        "book_type": "TaiLieuKhac"
    }
    # 1. T√¨m L·ªõp
    for part in path_parts:
        if part.startswith("Lop") and part[3:].isdigit():
            metadata["grade"] = part
            break
    # 2. T√¨m NXB
    for pub in KNOWN_PUBLISHERS:
        if pub in path_parts:
            metadata["publisher"] = pub
            break
    # 3. T√¨m Lo·∫°i s√°ch
    for b_type in KNOWN_TYPES:
        if b_type in path_parts:
            metadata["book_type"] = b_type
            break
    return metadata

def ingest_data():
    print("üöÄ B·∫Øt ƒë·∫ßu n·∫°p d·ªØ li·ªáu (Phi√™n b·∫£n ƒë√£ s·ª≠a l·ªói import)...")
    
    if not os.path.exists(DATA_ROOT):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c '{DATA_ROOT}'")
        return

    documents = []
    total_files = 0

    # Qu√©t file b·∫±ng os.walk (b·∫•t ch·∫•p c·∫•u tr√∫c th∆∞ m·ª•c)
    for root, dirs, files in os.walk(DATA_ROOT):
        for filename in files:
            if filename.endswith(".pdf"):
                file_path = os.path.join(root, filename)
                meta = get_metadata_from_path(file_path)
                
                if meta["grade"] != "Unknown":
                    try:
                        print(f"üìñ ƒê·ªçc: {filename} \t| {meta['grade']} - {meta['publisher']} - {meta['book_type']}")
                        loader = PyPDFLoader(file_path)
                        pages = loader.load()
                        
                        for page in pages:
                            page.metadata.update(meta)
                            page.metadata['source_file'] = filename
                            if page.page_content:
                                page.page_content = page.page_content.replace('\n', ' ')
                        
                        documents.extend(pages)
                        total_files += 1
                    except Exception as e:
                        print(f"‚ö†Ô∏è L·ªói file {filename}: {e}")

    if total_files == 0:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file PDF n√†o h·ª£p l·ªá.")
        return

    print(f"\nüì¶ T·ªïng: {total_files} file. ƒêang chia nh·ªè...")

    # --- S·ª¨ D·ª§NG CLASS T·ª™ G√ìI M·ªöI ---
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", ".", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"üß© S·ªë l∆∞·ª£ng chunks: {len(chunks)}")

    # --- X√ÅC NH·∫¨N: ƒê√É S·ª¨ D·ª§NG MODEL B·∫†N Y√äU C·∫¶U ---
    print("üß† ƒêang t·∫£i Model 'keepitreal/vietnamese-sbert'...")
    embedding_model = HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert", # <--- Ch√≠nh x√°c l√† model n√†y
        model_kwargs={'device': 'cpu'}
    )

    if os.path.exists(DB_PATH):
        shutil.rmtree(DB_PATH) # X√≥a DB c≈© ƒë·ªÉ l√†m s·∫°ch
        print("üóëÔ∏è  ƒê√£ x√≥a DB c≈©.")

    print("üíæ ƒêang l∆∞u v√†o ChromaDB...")
    db = Chroma.from_documents(chunks, embedding_model, persist_directory=DB_PATH)
    print(f"üéâ XONG! D·ªØ li·ªáu ƒë√£ l∆∞u t·∫°i: {DB_PATH}")

if __name__ == "__main__":
    ingest_data()